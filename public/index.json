[{"authors":null,"categories":null,"content":"My name is Zach DeBruine and I am a postdoctoral fellow in bioinformatics at the Van Andel Institute. I work in the Center for Epigenetics within the Triche Lab where I develop methods for analysis of single-cell experiments. I love simple, fast, and common sense data analysis.\nI developed the general-purpose Rcpp Machine Learning Library (RcppML) R package for non-negative factorization and clustering. This blog is my sandbox for trying new things, sharing stuff I\u0026rsquo;ve learned, and testing stuff I\u0026rsquo;ve built.\nThis blog is built with blogdown and Hugo, and deployed using Netlify.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://zachdebruine.com/author/zach-debruine/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/zach-debruine/","section":"authors","summary":"My name is Zach DeBruine and I am a postdoctoral fellow in bioinformatics at the Van Andel Institute. I work in the Center for Epigenetics within the Triche Lab where I develop methods for analysis of single-cell experiments.","tags":null,"title":"Zach DeBruine","type":"authors"},{"authors":null,"categories":["NMF","methods"],"content":"\rNMF Initialization\rNon-negative matrix factorization (NMF) is NP-hard (Vavasis, 2007). As such, the best that NMF can do, in practice, is find the best discoverable local minima from some set of initializations.\nNon-negative Double SVD (NNDSVD) has previously been proposed as a “head-start” for NMF (Boutsidis, 2008). However, SVD and NMF are usually nothing alike, as SVD factors are sequentially interdependent while NMF factors are colinearly interdependent. Thus, whether “non-negative” SVD is useful remains unclear.\nRandom initializations are the most popular and promising method for NMF initialization. It is generally useful to attempt many random initializations to discover the best possible solution.\nIn this post I explore a number of initializations on the hawaiibirds, aml, and movielens datasets, and a small single-cell dataset.\n\rTakeaways\r\rSVD-based initializations (such as NNDSVD) are slower than random initializations, sometimes do worse, and are never better.\rMultiple random initializations are useful for recovering the best discoverable NMF solution.\rNormal random distributions (i.e. rnorm(mean = 2, sd = 1)) slightly outperform uniform random distributions (i.e. runif(min = 1, max = 2)) at finding the best NMF solution.\r\r\rNon-negative Double SVD\rThe following is an implementation of NNDSVD, adapted from the NMF package. In this function, the use of irlba is a key performance improvement, and we do not do any form of zero-filling as I have found that this does not affect the outcome of RcppML NMF:\nnndsvd \u0026lt;- function(data, k) {\r.pos \u0026lt;- function(x) { as.numeric(x \u0026gt;= 0) * x }\r.neg \u0026lt;- function(x) {-as.numeric(x \u0026lt; 0) * x }\r.norm \u0026lt;- function(x) { sqrt(drop(crossprod(x))) }\rw = matrix(0, nrow(data), k)\rs = irlba::irlba(data, k)\rw[, 1] = sqrt(s$d[1]) * abs(s$u[, 1])\r# second SVD for the other factors\rfor (i in 2:k) {\ruu = s$u[, i]\rvv = s$v[, i]\ruup = .pos(uu)\ruun = .neg(uu)\rvvp = .pos(vv)\rvvn = .neg(vv)\rn_uup = .norm(uup)\rn_vvp = .norm(vvp)\rn_uun = .norm(uun)\rn_vvn = .norm(vvn)\rtermp = as.double(n_uup %*% n_vvp)\rtermn = as.double(n_uun %*% n_vvn)\rif (termp \u0026gt;= termn) {\rw[, i] = (s$d[i] * termp)^0.5 * uup / n_uup\r} else {\rw[, i] = (s$d[i] * termn)^0.5 * uun / n_uun\r}\r}\rw\r}\rWe can compare NNDSVD to normal SVD:\nlibrary(irlba)\rlibrary(RcppML)\rlibrary(ggplot2)\rdata(hawaiibirds)\rA \u0026lt;- hawaiibirds$counts\rm1 \u0026lt;- nndsvd(A, 2)\rm2 \u0026lt;- irlba(A, 2)\rdf \u0026lt;- data.frame(\u0026quot;svd2\u0026quot; = m2$u[,2], \u0026quot;nndsvd2\u0026quot; = m1[,2])\rggplot(df, aes(x = svd2, y = nndsvd2)) + geom_point() + labs(x = \u0026quot;second singular vector\u0026quot;, y = \u0026quot;second NNDSVD vector\u0026quot;) + theme_classic()\rWe might also derive a much simpler form of NNDSVD which simply sets negative values in $u to zero:\nnndsvd2 \u0026lt;- function(data, k){\rw \u0026lt;- irlba(data, k)$u\rsvd1 \u0026lt;- abs(w[,1])\rw[w \u0026lt; 0] \u0026lt;- 0\rw[,1] \u0026lt;- svd1\rw\r}\rFinally, we could simply initialize with the signed SVD, and let NMF take care of imposing the non-negativity constraints:\nw_svd \u0026lt;- function(data, k){\rirlba(data, k)$u\r}\r\rRandom Initializations\rWe can test different random initializations using runif and rnorm. Hyperparameters to runif are min and max, while hyperparameters to rnorm are mean and sd. In both cases, our matrix must be non-negative.\nw_runif \u0026lt;- function(nrow, k, min, max, seed){\rset.seed(seed)\rmatrix(runif(nrow * k, min, max), nrow, k)\r}\rw_rnorm \u0026lt;- function(nrow, k, mean, sd, seed){\rset.seed(seed)\rabs(matrix(rnorm(nrow * k, mean, sd), nrow, k))\r}\rGenerate some initial w matrices using these functions:\nlibrary(cowplot)\rw1 \u0026lt;- w_runif(nrow(A), 10, 0, 1, 123)\rw2 \u0026lt;- w_runif(nrow(A), 10, 1, 2, 123)\rw3 \u0026lt;- w_rnorm(nrow(A), 10, 0, 1, 123)\rw4 \u0026lt;- w_rnorm(nrow(A), 10, 2, 1, 123)\rSee how the distributions of these different models differ:\n\rEvaluating initialization methods\rWe’ll use Mean Squared Error as a simple evaluation metric. We will compare results across several different datasets, as signal complexity can have a profound effect on recoverable NMF solution minima.\nhawaiibirds dataset\rFirst, we’ll look at the hawaii birds dataset. Since this is a small dataset, we will run 50 replicates of each random initialization to 100 iterations.\ndata(hawaiibirds)\rresults \u0026lt;- eval_initializations(\rhawaiibirds$counts, k = 10, n_reps = 50, tol = 1e-10, maxit = 100)\rUMAP plot of all models learned for each initialization:\nClearly, rnorm(mean = 2, sd = 1) has discovered a local minima that was not discovered by any other initialization method. Strikingly, it has done so while running faster than other methods.\n\rmovielens dataset\rFor this dataset, we will mask zeros, because 0’s indicate movies that have not been rated by the corresponding users.\nWe will stop factorizations at tol = 1e-5 and also track the number of iterations needed to get to that point.\ndata(movielens)\rresults \u0026lt;- eval_initializations(\rmovielens$ratings, k = 7, n_reps = 10, tol = 1e-5, maxit = 1000, mask = \u0026quot;zeros\u0026quot;)\rUMAP plot of the learned models:\nModels here are much more similar, but rnorm still does surprisingly well, requires surprisingly few iterations, and is quite fast. Almost entirely on-par with this initialization is nndsvd.\n\raml dataset\rdata(aml)\rresults \u0026lt;- eval_initializations(aml, k = 10, n_reps = 25, tol = 1e-5)\rand a UMAP plot of the learned models:\n\rSingle-cell data\rLet’s have a look at the pbmc3k dataset made available in the SeuratData package. This dataset is an example of complex signal with significant dropout and noise.\nlibrary(Seurat)\rlibrary(SeuratData)\rpbmc3k\r## An object of class Seurat ## 13714 features across 2700 samples within 1 assay ## Active assay: RNA (13714 features, 0 variable features)\rpbmc \u0026lt;- pbmc3k@assays$RNA@counts\rresults_pbmc3k \u0026lt;- eval_initializations(pbmc, k = 7, n_reps = 20, tol = 1e-5)\r\rNormalized Single-Cell Data\rLog-normalize single cell data and see how these changes in the distribution affect the ideal initialization method:\npbmc_norm \u0026lt;- LogNormalize(pbmc)\rresults_pbmc_norm \u0026lt;- eval_initializations(pbmc_norm, k = 7, n_reps = 20, tol = 1e-5)\r\r\rTakeaways so far\rRuntime:\r* rnorm and runif. Consistently faster than SVD-based initializations. There is no convincing difference between rnorm and runif.\nLoss:\r* with multiple starts, rnorm(2, 1) never does worse than any other method, but performs worse on average than runif in single-cell data.\r* nndsvd performs as well as runif in aml and single-cell data, but takes longer. It performs worse than runif in movielens data (by a lot), and better than runif in hawaiibirds (but not as well as rnorm)\nIterations:\r* runif does at least as well as, or better than, all other methods.\nSpectral decompositions such as nndsvd do not out-perform random initialization-based methods such as rnorm or runif consistently. In addition, they require that an SVD be run, which increases the total runtime.\n\rOptimizing runif\rIt is possible that changing the bounds of the uniform distribution may affect the results.\nWe will address whether the width of the bounds matters, and the proximity of the lower-bound to zero. We will look at bounds in the range (0, 1), (0, 2), (0, 10), (1, 2), (1, 10), and (2, 10):\nresults_hibirds \u0026lt;- eval_runif(hawaiibirds$counts, k = 10, n_reps = 20, tol = 1e-6)\rresults_aml \u0026lt;- eval_runif(aml, k = 12, n_reps = 20)\rresults_movielens \u0026lt;- eval_runif(movielens$ratings, k = 7, n_reps = 20, mask = \u0026quot;zeros\u0026quot;)\rresults_pbmc \u0026lt;- eval_runif(pbmc, k = 7, n_reps = 20)\rThese results show no consistent recipe for finding the best minima, but that there is considerable dataset-specific variation.\nHowever, it is clear that varying the lower and upper bounds of runif across restarts is likely to be useful.\n\rOptimizing rnorm\rChanging the mean and standard deviation of the absolute value of a normal distribution can generate non-normal distributions, in fact, it can generate distributions quite like a gamma distribution. Thus, we will investigate some different combinations of mean and standard deviation: (0, 0.5), (0, 1), (0, 2), (1, 0.5), (1, 1), and (2, 1):\nresults_hibirds \u0026lt;- eval_rnorm(hawaiibirds$counts, k = 10, n_reps = 20, tol = 1e-6)\rresults_aml \u0026lt;- eval_rnorm(aml, k = 12, n_reps = 20)\rresults_movielens \u0026lt;- eval_rnorm(movielens$ratings, k = 7, n_reps = 20, mask = \u0026quot;zeros\u0026quot;)\rresults_pbmc \u0026lt;- eval_rnorm(pbmc, k = 7, n_reps = 20)\rHere it’s more difficult to pick a winner, they really perform similarly. For the pbmc3k dataset, however, rnorm(2,1) is probably the best choice. This distribution is largely normal, as opposed to gamma (i.e. rnorm(0, 0.5), which could be seen as the “loser”) or a lopsided bell-curve shaped (i.e. `rnorm(1, 1)).\n\r","date":1634688000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634743735,"objectID":"0a0f0316ebe86b65fb65942739d9e39b","permalink":"https://zachdebruine.com/post/learning-optimal-nmf-models-from-random-restarts/","publishdate":"2021-10-20T00:00:00Z","relpermalink":"/post/learning-optimal-nmf-models-from-random-restarts/","section":"post","summary":"Finding the best discoverable solution for a non-negative matrix factorization from a random initialization requires multiple random restarts. NNDSVD has previously been proposed as a \"head-start\" for NMF, but I show that it is not always a head start, and can be a dangerous local minima. I further explore the use of random uniform or random gaussian models for NMF initialization.","tags":["NMF","initialization"],"title":"Learning Optimal NMF Models from Random Restarts","type":"post"},{"authors":null,"categories":["NMF","methods"],"content":"\rKey Takeaways\rFor non-negative matrix factorization:\n\rL1 and L2 regularization require diagonalization (factorization of the form \\(A = wdh\\))\rL1 is a sparsifying, L2 is densifying\rL1 increases angle between factors, L2 decreases angle between factors\rL1 penalties cause factors to converge collectively towards a k-means clustering model, L2 penalties cause each factor to converge individually towards the first singular vector\r\r\rRegularizing NMF\rRegularizations are intended to improve the interpretability or identifiability of linear models. Consider the least squares problem \\(ax = b\\), for which common regularizations include:\n\rL1/LASSO regularization: absolute shrinkage, penalty subtracted from \\(b\\)\rL2/Ridge regularization: convex shrinkage, penalty added to diagonal of \\(a\\)\r\rIn a typical non-negative least squares (NNLS) fit, these regularizations behave usefully. For example, an L1 penalty equal to the maximum value in \\(b\\) will ensure complete sparsity of the solution.\nNow consider NMF by alternating least squares. NMF differs from one-off least squares problems in several ways:\n\rIt is iterative\rThe initial distribution of the models are unknown (i.e. projection of random factors)\rThe distribution of a model at a given iteration is dependent on that of the models at all previous iterations\r\rThus, NMF regularizations have a chain effect: a change in one iteration will lead to a change in information and distribution in the next, and so forth. Thus, if the distribution of the model is not controlled after each update, penalties will cause the model to spiral out of control.\n\rControlling NMF model distributions during updates\rNMF minimizes \\(A = wh\\). The least squares update of \\(h\\), column \\(j\\) given \\(A\\) and \\(w\\) is:\n\\[w^Twh_j = w^TA_j\\]\nCorrespondingly, the least squares update of \\(w\\), row \\(j\\), given \\(A\\) and \\(h\\) is:\n\\[hh^Tw_j = hA^T_j\\]\rThese equations are in the form \\(ax = b\\). For instance, in the update of \\(h\\), \\(a = w^Tw\\) and \\(b = w^TA_j\\).\nFor a regularization penalty strictly in the range (0, 1], we want to guarantee that the penalty will be consistent across random NMF restarts, different datasets, and across alternating least squares updates. To guarantee consistent application of the penalty, we need to control the distribution of \\(a\\) and \\(b\\).\nThe distribution of a model can be controlled by diagonalizing the NMF model, such that \\(A = wdh\\), where columns in \\(w\\) and rows in \\(h\\) are scaled to sum to 1 by a scaling diagonal, \\(d\\). Factors need not scale to 1, it could be any constant value, but 1 provides nice interpretability.\n\rDiagonalized NMF enables convex regularization\rLet’s load the hawaiibirds dataset and factorize the data at several L1 and L2 penalties, with and without model diagonalization, also calculating various statistics such as sparsity, similarity to k-means clustering, and similarity to the first singular vector.\n# devtools::install_github(\u0026quot;zdebruine/RcppML\u0026quot;)\rlibrary(RcppML)\rdata(hawaiibirds)\rA \u0026lt;- hawaiibirds$counts\ralphas \u0026lt;- c(c(1, 3, 5, 9) %o% 10^(-3:-1)) # c(seq(0, 0.1, 0.005), seq(0.11, 0.5, 0.01)) # seq(0, 0.98, 0.02)\rseeds \u0026lt;- c(123, 456, 789)\rkmeans_centers \u0026lt;- t(kmeans(t(as.matrix(A)), 10)$centers)\rsvd1 \u0026lt;- nmf(A, 1)@w\rdf \u0026lt;- data.frame()\rfor(alpha in alphas){\rfor(seed in seeds){\rfor(diag in c(FALSE, TRUE)){\rm \u0026lt;- nmf(A, 10, seed = seed, diag = diag)\rfor(penalty in c(\u0026quot;L1\u0026quot;, \u0026quot;L2\u0026quot;)){\rm_ \u0026lt;- nmf(A, 10, seed = seed, diag = diag,\rL1 = ifelse(penalty == \u0026quot;L1\u0026quot;, alpha, 0), L2 = ifelse(penalty == \u0026quot;L2\u0026quot;, alpha, 0),\r)\rdf \u0026lt;- rbind(df, data.frame(\r\u0026quot;alpha\u0026quot; = alpha,\r\u0026quot;seed\u0026quot; = seed,\r\u0026quot;diag\u0026quot; = diag,\r\u0026quot;penalty\u0026quot; = penalty,\r\u0026quot;sparsity\u0026quot; = sum(m_@w == 0) / prod(dim(m_@w)),\r\u0026quot;robustness\u0026quot; = 1 - bipartiteMatch(1 - cosine(m_@w, m@w))$cost/10,\r\u0026quot;mse\u0026quot; = evaluate(m_, A),\r\u0026quot;mean_angle\u0026quot; = mean(cosine(m_@w)),\r\u0026quot;kmeans\u0026quot; = bipartiteMatch(1 - cosine(kmeans_centers, m_@w))$cost/10,\r\u0026quot;svd1\u0026quot; = sum(cosine(m_@w, svd1))/10,\r\u0026quot;color\u0026quot; = ifelse(penalty == \u0026quot;L1\u0026quot;, alpha^0.25, -alpha^0.25)\r)) }\r}\r}\r}\rdf$penalty \u0026lt;- factor(df$penalty)\rdf$seed \u0026lt;- factor(df$seed)\rTakeaways:\n\rDiagonal scaling guarantees consistent regularization between independent replicates (compare a, c with b, d)\rL1 regularization increases sparsity of factor models (b) while L2 regularization promotes density of the model (d)\rL1 = 1 guarantees complete sparsity (b) while L2 = 1 guarantees complete density (d)\r\rWe might not have expected that L2 is a densifying factorization. Why is this? L2 convexly shrinks values towards zero, and as such decreases the condition number of \\(a\\). This means signals will be encouraged to “squash” together, and factors in the resulting model will begin to describe similar signal. As this occurs, the model naturally becomes denser until a point is reached that the objective is minimized (at convergence).\n\rProperties of L1- and L2-regularized NMF\rLet’s consider how L1 and L2 regularizations affect the robustness of information content of factor models relative to the unregularized equivalent, and how they affect the mean squared error loss of the models.\nAs a measure of the robustness of information content, we use the mean cost of bipartite matching between L1-regularized and unregularized \\(w\\) models on a cosine similarity matrix.\nNotice how the L2 penalties tend to be much harsher than the L1 penalties. However, both penalties cause movement of the model away from the unregularized state.\nWithin the models themselves, we can examine how similar factors are to one another by measuring the mean cosine angle:\nggplot(subset(df, diag == TRUE \u0026amp; seed == 123), aes(x = alpha, y = mean_angle, color = penalty)) +\rgeom_point() + labs(x = \u0026quot;alpha\u0026quot;, y = \u0026quot;mean cosine angle\\nbetween factors\u0026quot;) +\rtheme_classic() + theme(aspect.ratio = 1) + scale_x_continuous(trans = \u0026quot;sqrt\u0026quot;) +\rstat_smooth(se = F)\rWe can see that L1 penalty increases the distance between factors, while L2 penalty increases the similarity between factors.\nNow let’s take a look at how L1 and L2 penalties affect the sparsity of factors, and also calculate the similarity of these models to a k-means clustering or the first singular vector (given by a rank-1 NMF):\nL1 is sparsifying while L2 is densifying.\nHere, L1 promotes a k-means clustering model while L2 promotes convergence towards the first singular vector.\n\rInterpreting L1- and L2-regularized factor models\rWe’ll select regularization parameters for further analysis based on a cosine angle of about 0.25 away from the original model:\nmodel \u0026lt;- nmf(A, 10, tol = 1e-6, seed = 123)\rmodel_L1 \u0026lt;- nmf(A, 10, tol = 1e-6, seed = 123, L1 = 0.2)\rmodel_L2 \u0026lt;- nmf(A, 10, tol = 1e-6, seed = 123, L2 = 0.02)\rTake a look at the clustering of factors in the \\(w\\) models on UMAP coordinates:\nSimilar information is clearly being captured by each of the models, but let’s see in what way.\nWe’ll align factors in the regularized models to the unregularized models, and then compare specific factors.\nlibrary(ggrepel)\rbiplot \u0026lt;- function(model1, model2, factor){\rdf \u0026lt;- data.frame(\u0026quot;model1\u0026quot; = model1$w[, factor], \u0026quot;model2\u0026quot; = model2$w[, factor], \u0026quot;label\u0026quot; = rownames(model1$w))\rggplot(df, aes(x = model1, y = model2, label = label)) + geom_point() + theme_classic() + geom_text_repel(size = 2.5)\r}\rmodel_L1 \u0026lt;- align(model_L1, model)\rmodel_L2 \u0026lt;- align(model_L2, model)\rThese are very harsh penalties, so notice how L1 can over-sparsify things, while L2 can generate factors that are so dense the information is hardly specific or informative.\nA happy medium for sparsifying (or densifying) regularization certainly exists, and this is an objective hyperparameter that must be determined against the objectives of the analysis. Unfortunately, there is nothing against which to optimize – this appears to be a matter of statistical taste.\n\rFuture directions\r\rEffect of L1 and L2 regularizations on factorization rank\rIntuition behind one-sided L1 and L2 regularization\rIntuition behind combined L1/L2 or one-sided L1 vs. one-sided L2\r\r\r","date":1634515200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634515200,"objectID":"343418ecd882c05df57e032509cf7ba1","permalink":"https://zachdebruine.com/post/l2-regularized-nmf/","publishdate":"2021-10-18T00:00:00Z","relpermalink":"/post/l2-regularized-nmf/","section":"post","summary":"L1- and L2-regularized non-negative matrix factorizations have special properties. Here I show how L1 is a sparsifying regularization that promotes a k-means clustering-like model, while L2 is a densifying regularization that promotes convergence of all factors towards the first singular vector.","tags":["NMF","regularization","L2"],"title":"Statistical properties of L1- and L2-regularized NMF","type":"post"},{"authors":null,"categories":["NMF","methods"],"content":"\rCross-Validation for NMF\rRank is the most important hyperparameter in NMF. Finding that “sweet spot” rank can make the difference between learning a useful model that captures meaningful signal (but not noise) or learning a garbage model that misses good signal or focuses too much on useless noise.\nAlex Williams has posted a great introduction to cross-validation for NMF on his blog. His review of the first two methods is particularly intuitive. However, the third method is both theoretically questionable and poor in practice.\nThere are three “unsupervised” cross-validation methods for NMF which I have found to be useful:\n\rBi-cross-validation, proposed by Perry and explained simply by Williams. The “Bi-” in “Bi-cross-validation” means that the model is trained on a block of randomly selected samples and features and evaluated on a non-intersecting block of samples and features. Thus, no samples or features in the test set are included in the training set. If the test and training sets contain samples in common, or features in common, NMF gets to “cheat” in training and directly infer patterns of regulation, and thus basic subsample-cross-validation with NMF does not work.\rImputation, described nicely by Lin and also reviewed in this StackExchange post by amoeba. Here, a small fraction of values (i.e. 5%) are “masked” and considered as missing during factorization, and the mean squared error of the imputed values is calculated after model training.\rRobustness is simply the cosine similarity of matched factors in independent models trained on non-overlapping sample sets. The premise is that noise capture will result in low similarity, while efficient signal capture will result in high similarity. Furthermore, approximations which are too low-rank will not classify signals in the same manner, leading to poor factor matching.\r\r\rTakeaways\r\rThe project method (bi-cross-validation) is useful for well-conditioned signal.\rThe robust method (similarity of independent factorizations) is generally the most informative for noisy data possibly suffering from signal dropout.\rThe imputation method is the slowest of the three, but generally the most sensitive.\r\r\rInstall RcppML\rInstall the development version of RcppML:\ndevtools::install_github(\u0026quot;zdebruine/RcppML\u0026quot;)\rlibrary(RcppML)\rlibrary(ggplot2)\rlibrary(cowplot)\rlibrary(umap)\rlibrary(irlba)\r\rSimulated data\rSimulated data is useful for demonstrating the utility of methods in response to adversarial perturbations such as noise or dropout.\nWe will first explore cross-validation using two simulated datasets generated with simulateNMF:\ndata_clean will have no noise or signal dropout\rdata_dirty contains the same signal as data_clean, but with a good amount of noise and dropout.\r\rdata_clean \u0026lt;- simulateNMF(nrow = 200, ncol = 200, k = 5, noise = 0, dropout = 0, seed = 123)\rdata_dirty \u0026lt;- simulateNMF(nrow = 200, ncol = 200, k = 5, noise = 0.5, dropout = 0.5, seed = 123)\rNotice how data_clean contains only 5 non-zero singular values, while data_dirty does not:\nWe can use RcppML::crossValidate to determine the rank of each dataset. The default method uses “bi-cross-validation”. See ?crossValidate for details.\ncv_clean \u0026lt;- crossValidate(data_clean, k = 1:10, method = \u0026quot;predict\u0026quot;, reps = 3, seed = 123)\rcv_dirty \u0026lt;- crossValidate(data_dirty, k = 1:10, method = \u0026quot;predict\u0026quot;, reps = 3, seed = 123)\rplot_grid(\rplot(cv_clean) + ggtitle(\u0026quot;bi-cross-validation on\\nclean dataset\u0026quot;),\rplot(cv_dirty) + ggtitle(\u0026quot;bi-cross-validation on\\ndirty dataset\u0026quot;), nrow = 1)\rcrossValidate also supports another method which compares robustness of two factorizations on independent sample subsets.\ncv_clean \u0026lt;- crossValidate(data_clean, k = 1:10, method = \u0026quot;robust\u0026quot;, reps = 3, seed = 123)\rcv_dirty \u0026lt;- crossValidate(data_dirty, k = 1:10, method = \u0026quot;robust\u0026quot;, reps = 3, seed = 123)\rplot_grid(\rplot(cv_clean) + ggtitle(\u0026quot;robust cross-validation on\\nclean dataset\u0026quot;),\rplot(cv_dirty) + ggtitle(\u0026quot;robust cross-validation on\\ndirty dataset\u0026quot;), nrow = 1)\rThis second method does better on ill-conditioned data because it measures the robustness between independent factorizations.\nFinally, we can use the impute method:\ncv_clean \u0026lt;- crossValidate(data_clean, k = 1:10, method = \u0026quot;impute\u0026quot;, reps = 3, seed = 123)\rcv_dirty \u0026lt;- crossValidate(data_dirty, k = 1:10, method = \u0026quot;impute\u0026quot;, reps = 3, seed = 123)\rplot_grid(\rplot(cv_clean) + ggtitle(\u0026quot;impute cross-validation on\\nclean dataset\u0026quot;) + scale_y_continuous(trans = \u0026quot;log10\u0026quot;),\rplot(cv_dirty) + ggtitle(\u0026quot;impute cross-validation on\\ndirty dataset\u0026quot;) + scale_y_continuous(trans = \u0026quot;log10\u0026quot;), nrow = 1)\rFor real datasets, it is important to experiment with both cross-validation methods and to explore multi-resolution analysis or other objectives where appropriate.\nLet’s take a look at a real dataset:\n\rFinding the rank of the hawaiibirds dataset\rdata(hawaiibirds)\rA \u0026lt;- hawaiibirds$counts\rcv_predict \u0026lt;- crossValidate(A, k = 1:20, method = \u0026quot;predict\u0026quot;, reps = 3, seed = 123)\rcv_robust \u0026lt;- crossValidate(A, k = 1:20, method = \u0026quot;robust\u0026quot;, reps = 3, seed = 123)\rcv_impute \u0026lt;- crossValidate(A, k = 1:20, method = \u0026quot;impute\u0026quot;, reps = 3, seed = 123)\rplot_grid(\rplot(cv_predict) + ggtitle(\u0026quot;method = \u0026#39;predict\u0026#39;\u0026quot;) + theme(legend.position = \u0026quot;none\u0026quot;),\rplot(cv_robust) + ggtitle(\u0026quot;method = \u0026#39;robust\u0026#39;\u0026quot;) + theme(legend.position = \u0026quot;none\u0026quot;),\rplot(cv_impute) + ggtitle(\u0026quot;method = \u0026#39;impute\u0026#39;\u0026quot;) + scale_y_continuous(trans = \u0026quot;log10\u0026quot;) + theme(legend.position = \u0026quot;none\u0026quot;),\rget_legend(plot(cv_predict)), rel_widths = c(1, 1, 1, 0.4), nrow = 1, labels = \u0026quot;auto\u0026quot;)\r\rFinding the rank of the aml dataset\rdata(aml)\rcv_impute \u0026lt;- crossValidate(aml, k = 2:14, method = \u0026quot;impute\u0026quot;, reps = 3, seed = 123)\rplot(cv_impute) + scale_y_continuous(trans = \u0026quot;log10\u0026quot;)\r\rTechnical considerations\rRuntime is a major consideration for large datasets. Unfortunately, missing value imputation can be very slow.\n\rPerturb\rCompare missing value imputation with perturb (zeros) and perturb (random):\ndata(hawaiibirds)\rdata(aml)\rdata(movielens)\rlibrary(Seurat)\r## Warning: package \u0026#39;Seurat\u0026#39; was built under R version 4.0.5\r## Attaching SeuratObject\rlibrary(SeuratData)\r## Registered S3 method overwritten by \u0026#39;cli\u0026#39;:\r## method from ## print.boxx spatstat.geom\r## -- Installed datasets ------------------------------------- SeuratData v0.2.1 --\r## v bmcite 0.3.0 v pbmc3k 3.1.4\r## v hcabm40k 3.0.0 v pbmcMultiome 0.1.0\r## v ifnb 3.1.0 v pbmcsca 3.0.0\r## v panc8 3.0.2 v stxBrain 0.1.1\r## -------------------------------------- Key -------------------------------------\r## v Dataset loaded successfully\r## \u0026gt; Dataset built with a newer version of Seurat than installed\r## (?) Unknown version of Seurat installed\rpbmc3k\r## An object of class Seurat ## 13714 features across 2700 samples within 1 assay ## Active assay: RNA (13714 features, 0 variable features)\rA \u0026lt;- pbmc3k@assays$RNA@counts\rn \u0026lt;- 0.2\rmethod = \u0026quot;impute\u0026quot;\rcv1 \u0026lt;- crossValidate(A, k = 1:15, method = method, reps = 3, seed = 123, perturb_to = \u0026quot;random\u0026quot;, n = n)\rcv2 \u0026lt;- crossValidate(aml, k = 1:15, method = method, reps = 3, seed = 123, perturb_to = \u0026quot;random\u0026quot;, n = n)\rcv3 \u0026lt;- crossValidate(movielens$ratings, k = 1:15, method = method, reps = 3, seed = 123, perturb_to = \u0026quot;random\u0026quot;, n = n)\rcv4 \u0026lt;- crossValidate(hawaiibirds$counts, k = 1:15, method = method, reps = 3, seed = 123, perturb_to = \u0026quot;random\u0026quot;, n = n)\rplot_grid(\rplot(cv1) + theme(legend.position = \u0026quot;none\u0026quot;) + scale_y_continuous(trans = \u0026quot;log10\u0026quot;),\rplot(cv2) + theme(legend.position = \u0026quot;none\u0026quot;) + scale_y_continuous(trans = \u0026quot;log10\u0026quot;),\rplot(cv3) + theme(legend.position = \u0026quot;none\u0026quot;) + scale_y_continuous(trans = \u0026quot;log10\u0026quot;),\rplot(cv4) + theme(legend.position = \u0026quot;none\u0026quot;) + scale_y_continuous(trans = \u0026quot;log10\u0026quot;),\rnrow = 2)\r\r","date":1634428800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634428800,"objectID":"e7e903eaf2ef8d1e3bb5e7071111c38f","permalink":"https://zachdebruine.com/post/cross-validation-for-nmf-rank-determination/","publishdate":"2021-10-17T00:00:00Z","relpermalink":"/post/cross-validation-for-nmf-rank-determination/","section":"post","summary":"In this post I review four distinctly different methods for cross-validation of NMF, each with strengths and weaknesses for different applications, and discuss how to use these methods effectively.","tags":["NMF","cross-validation"],"title":"Cross-validation for NMF rank determination","type":"post"},{"authors":null,"categories":["NMF","annotation"],"content":"\rAnnotating NMF factors\rNMF learns an interpretable low-rank representation of data. However, how do we make sense of the factors in this low-rank latent model? A great way to begin annotating a latent space is to simply map it back to known sample and feature traits.\nThis vignette demonstrates these concepts using an NMF model of bird species communities throughout the Hawaiian islands.\n\rInstall RcppML\rInstall the RcppML R package from CRAN or the development version from GitHub. Also install the accompanying Machine Learning datasets (MLdata) package:\ninstall.packages(\u0026#39;RcppML\u0026#39;) # install CRAN version\r# devtools::install_github(\u0026quot;zdebruine/RcppML\u0026quot;) # compile dev version\rdevtools::install_github(\u0026quot;zdebruine/MLdata\u0026quot;)\rlibrary(RcppML)\rlibrary(MLdata)\rlibrary(ggplot2)\rlibrary(cowplot)\rlibrary(viridis)\rlibrary(ggrepel)\rlibrary(uwot)\r\rThe hawaiibirds dataset\rThe MLdata::hawaiibirds dataset gives the frequency of bird species in small geographical grids throughout the state of Hawaii.\ndata(hawaiibirds)\rhawaiibirds$counts[1:4, 1:4]\r## 4 x 4 sparse Matrix of class \u0026quot;dgCMatrix\u0026quot;\r## grid1 grid2 grid3 grid4\r## Common Myna 0.32432432 0.19230769 0.242753623 0.80208333\r## Black-crowned Night-Heron 0.06756757 0.07692308 0.007246377 0.03819444\r## Black Noddy . 0.26923077 0.188405797 . ## Brown Noddy . 0.38461538 . .\rA separate metadata_h matrix gives the geographical coordinates and the corresponding island for each grid.\nhead(hawaiibirds$metadata_h)\r## grid island lat lng\r## 1 grid1 Maui 20.87 -156.44\r## 2 grid2 Oahu 21.33 -157.66\r## 3 grid3 Hawaii 19.33 -155.19\r## 4 grid4 Oahu 21.37 -157.94\r## 5 grid5 Hawaii 19.72 -155.11\r## 6 grid6 Maui 20.74 -156.24\rAnd a separate metadata_w matrix gives taxonomic information about each species in the database.\nhead(hawaiibirds$metadata_w)\r## species order\r## 1 Common Myna Passeriformes\r## 2 Black-crowned Night-Heron Pelecaniformes\r## 3 Black Noddy Charadriiformes\r## 4 Brown Noddy Charadriiformes\r## 5 Bulwer\u0026#39;s Petrel Procellariiformes\r## 6 Sooty Tern Charadriiformes\r## family category status\r## 1 Sturnidae (Starlings) perching birds introduced\r## 2 Ardeidae (Herons, Egrets, and Bitterns) waders native\r## 3 Laridae (Gulls, Terns, and Skimmers) shorebirds native\r## 4 Laridae (Gulls, Terns, and Skimmers) shorebirds native\r## 5 Procellariidae (Shearwaters and Petrels) seabirds native\r## 6 Laridae (Gulls, Terns, and Skimmers) shorebirds native\r\rCross-validation for Rank Determination\rWe can learn an NMF model to describe linear combinations of species across geographical grids. First we need to choose a rank.\nThe rank of a factorization is a crucial hyperparameter. One way to help decide on a rank is cross-validation. This is made easy using the crossValidate function. See ?crossValidate for details on methods.\nFor many applications, there is no “optimal” rank. In this case, we do expect some amount of distinct biodiversity across the various islands, but within the islands there will be a continuum of habitat niches confounding rank of the signal. Additionally, there may be a number of “missing” observations where surveys were incomplete, which will confound signal separation.\nHere we cross-validate across 3 independent replicates and plot the result:\nplot(crossValidate(hawaiibirds$counts, k = c(1:10, 12, 15, 20, 25, 30), reps = 3, verbose = FALSE))\rWe’ll choose a rank of k = 10 since this seems to capture much of the signal while giving identifiable factors.\n\rRun robust NMF\rLet’s generate a high-quality NMF model across 10 random restarts at very low tolerance:\nmodel \u0026lt;- nmf(hawaiibirds$counts, k = 10, seed = 1:10, tol = 1e-6)\rmodel\r## 183 x 1183 x 10 factor model of class \u0026quot;nmf\u0026quot;\r## $ w\r## nmf1 nmf2 nmf3 nmf4 nmf5\r## Common Myna 0.146640316 0.094888073 0.074299917 0.04111043 0\r## Black-crowned Night-Heron 0.006777407 0.004027294 0.005781633 0.00000000 0\r## Black Noddy 0.000000000 0.006376501 0.000000000 0.00000000 0\r## Brown Noddy 0.000000000 0.000000000 0.000000000 0.00000000 0\r## Bulwer\u0026#39;s Petrel 0.000000000 0.000000000 0.000000000 0.00000000 0\r## ...suppressing 178 rows and 5 columns\r## ## $ d\r## [1] 1350.6295 1256.2949 1153.2389 911.6537 834.4069\r## ...suppressing 5 values\r## ## $ h\r## grid1 grid2 grid3 grid4 grid5\r## nmf1 0.0009274172 0.0004718018 0.0005553570 0.003512579 0.0006238265\r## nmf2 0.0001676291 0.0002334082 0.0009073722 0.000000000 0.0018705609\r## nmf3 0.0005758524 0.0000000000 0.0000000000 0.000000000 0.0005398256\r## nmf4 0.0000000000 0.0003021981 0.0000000000 0.003822848 0.0000000000\r## nmf5 0.0000000000 0.0000000000 0.0011624112 0.000000000 0.0000000000\r## ...suppressing 5 rows and 1178 columns\r## ## $ tol: 8.238107e-07 ## $ iter: 67 ## $ runtime: 0.9558601 sec\rIn the w matrix we have factors describing communities of co-occuring bird species.\nIn the h matrix we have the association of these bird communities in each surveyed geographical grid.\n\rGeographic focus on NMF factors\rWhat does each NMF factor tell us?\nThe sample embeddings matrix (h) gives information about the geographical representation of each NMF factor across all grids. We’ll look at just the first four factors:\nplots \u0026lt;- list()\rfor(i in 1:4){\rdf \u0026lt;- data.frame(\r\u0026quot;lat\u0026quot; = hawaiibirds$metadata_h$lat,\r\u0026quot;lng\u0026quot; = hawaiibirds$metadata_h$lng,\r\u0026quot;nmf_factor\u0026quot; = model$h[i, ])\rplots[[i]] \u0026lt;- ggplot(df, aes(x = lng, y = lat, color = nmf_factor)) +\rgeom_point() +\rscale_color_viridis(option = \u0026quot;B\u0026quot;) +\rtheme_void() +\rtheme(legend.position = \u0026quot;none\u0026quot;, plot.title = element_text(hjust = 0.5)) + ggtitle(paste0(\u0026quot;Factor \u0026quot;, i))\r}\rplot_grid(plotlist = plots, nrow = 2)\r\rMetadata enrichment in factors\rFactor 2 is localized largely to the island of Hawaii, factor 3 to the island of Kauai, and factor 4 to Oahu.\nQuantitatively, the summary method for the nmf S3 class makes it easy to annotate factors using metadata about samples or features. See ?summary.nmf for info.\nIn this case, we will use summary to map factor enrichment in grids corresponding to each Hawaiian island, and species enrichment corresponding to each category.\nplot(summary(model, group_by = hawaiibirds$metadata_h$island, stat = \u0026quot;sum\u0026quot;))\rIn general, grids separate based on the island to which they belong – consistent with the expectation that islands contain distinct species communities.\nNotice how several factors explain variation within the big island, “Hawaii”, consistent with the objective of NMF and the biological diversity within that island.\nDue to our normalization method (sum) very small islands with minor contribution to the model objective (i.e. Puuwai) are hardly represented.\nplot(summary(model, group_by = hawaiibirds$metadata_w$category, stat = \u0026quot;mean\u0026quot;))\rClearly, there is the greatest signal complexity among “perching birds”. nmf10 is describing “seabirds” while nmf9 is capturing much of the “non-perching birds” information.\n\rNMF biplots\rCompare species composition in two factors that are both primarily restricted to the island of Hawaii, factors 7 and 8. The biplot S3 method for nmf makes this easy:\nbiplot(model, factors = c(7, 8), matrix = \u0026quot;w\u0026quot;, group_by = hawaiibirds$metadata_w$category) + scale_y_continuous(trans = \u0026quot;sqrt\u0026quot;) + scale_x_continuous(trans = \u0026quot;sqrt\u0026quot;) +\rgeom_text_repel(size = 2.5, seed = 123, max.overlaps = 15)\rFactor 7 describes a wet rainforest community while Factor 8 describes dry rainforest/shrubland communities. Both factors are overwhelmingly focused on “perching birds”.\n\rUMAP on NMF embeddings\rWe might also be interested in visualizing how factors in \\(w\\) capture similarities among bird species using UMAP.\nset.seed(123)\rumap \u0026lt;- data.frame(uwot::umap(model$w))\rumap$taxon \u0026lt;- hawaiibirds$metadata_w$category\rumap$status \u0026lt;- hawaiibirds$metadata_w$status\rplot_grid(\rggplot(umap, aes(x = umap[,1], y = umap[,2], color = taxon)) +\rgeom_point() + theme_void(),\rggplot(umap, aes(x = umap[,1], y = umap[,2], color = status)) +\rgeom_point() + theme_void(),\rnrow = 1\r)\rSpecies are classified based on habitat niche and taxonomic membership. Notice “seabirds” on the left, “perching birds” in the center mixed with “non-perching birds”, and a mix of “waders”, “waterfowl”, and “shorebirds” in the bottom right. There are also two distinct groups of “shorebirds” and “waterfowl”, consistent with distinct inland and shoreline communities.\nHawaii is extinction kingdom. For instance, more than 20 species of endemic honeycreeper have gone extinct in the past two centuries due to the establishment of introduced species and habitat devastation. Few remain. In the UMAP plot above on the right, we can observe that introduced species dominate habitat niches occupied by native perching and non-perching birds, a problem underlying historic and ongoing mass extinction events.\nset.seed(123)\rumap \u0026lt;- data.frame(uwot::umap(t(model$h)))\rumap$group \u0026lt;- hawaiibirds$metadata_h$island\rggplot(umap, aes(x = umap[,1], y = umap[,2], color = group)) +\rgeom_point() + theme_void()\rIslands are also well-defined by the NMF model.\n\rDefining the “Palila” species niche\rThe Palila is a highly endangered species that survives in small numbers on the eastern slopes of Mauna Kea on the dry island, in a shrubby dry “rainforest” biome. This biome is unique on the island of Hawaii.\nWhat species coexist with the Palila?\nLet’s find the highest factorization resolution at which a single factor describes the distribution of the Palila.\npalila \u0026lt;- list()\rfor(rank in 1:20)\rpalila[[rank]] \u0026lt;- data.frame(\r\u0026quot;value\u0026quot; = nmf(hawaiibirds$counts, k = rank, seed = 123, v = F)$w[\u0026quot;Palila\u0026quot;, ],\r\u0026quot;rank\u0026quot; = rep(rank, rank)\r)\rpalila \u0026lt;- do.call(rbind, palila)\rggplot(palila, aes(x = rank, y = value, color = factor(rank))) + geom_jitter(width = 0.1) + theme_classic() +\rscale_color_manual(values = rep(c(\u0026quot;#F8766D\u0026quot;, \u0026quot;#00BDD0\u0026quot;), 10)) + labs(\u0026quot;Palila loading in factor\u0026quot;) + theme(legend.position = \u0026quot;none\u0026quot;)\rThe model with a rank of 15 contains a factor in which the Palila is both important and specific.\nLet’s have a look at the species composition in factor 15, specifically identifying which species are introduced and which are native:\nmodel \u0026lt;- nmf(hawaiibirds$counts, k = 15, seed = 123, v = F)\rdf \u0026lt;- data.frame(\u0026quot;value\u0026quot; = model$w[, which.max(model$w[\u0026quot;Palila\u0026quot;, ])])\rdf$status \u0026lt;- hawaiibirds$metadata_w$status\rdf \u0026lt;- df[order(-df$value), ]\rdf \u0026lt;- df[df$value \u0026gt; 0.001, ]\rdf\r## value status\r## Hawaii Amakihi 0.353110902 native\r## Warbling White-eye 0.188662129 native\r## House Finch 0.182132197 introduced\r## Erckel\u0026#39;s Francolin 0.066866618 introduced\r## Yellow-fronted Canary 0.045745828 introduced\r## California Quail 0.043372489 native\r## Palila 0.038791926 native\r## Eurasian Skylark 0.032193106 introduced\r## Hawaii Elepaio 0.028948444 native\r## Red-billed Leiothrix 0.008899639 introduced\r## Chukar 0.004825709 introduced\r## Indian Peafowl 0.003265103 native\r## Chinese Hwamei 0.002520935 introduced\rThe diet of the Palilla is largely seeds from the “mamame” tree, but also naio berries and mamame flowers, buds, and young leaves. What introduced perching birds may be competing with the Palila for these resources?\nperching_birds \u0026lt;- hawaiibirds$metadata_w$species[hawaiibirds$metadata_w$category == \u0026quot;perching birds\u0026quot;]\rdf[which(rownames(df) %in% perching_birds \u0026amp; df$status == \u0026quot;introduced\u0026quot;), ]\r## value status\r## House Finch 0.182132197 introduced\r## Yellow-fronted Canary 0.045745828 introduced\r## Eurasian Skylark 0.032193106 introduced\r## Red-billed Leiothrix 0.008899639 introduced\r## Chinese Hwamei 0.002520935 introduced\rThe “House Finch” and “Yellow-fronted Canary” seem to be the most significant competitors in the Palila habitat niche.\n\r","date":1633996800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633996800,"objectID":"6f36f872236bb04d1e60b3c7d4ceac00","permalink":"https://zachdebruine.com/post/annotating-nmf-factors-with-sample-metadata/","publishdate":"2021-10-12T00:00:00Z","relpermalink":"/post/annotating-nmf-factors-with-sample-metadata/","section":"post","summary":"Use the Hawaii Birds dataset to show how to annotate factors in NMF models using metadata, with some interesting UMAP visualizations and applications to ecology along the way.","tags":["NMF","annotation"],"title":"Annotating NMF factors with sample metadata","type":"post"},{"authors":null,"categories":["NMF","integration"],"content":"\rNMF for source separation\rOne of the many applications of NMF is source separation, aka blind signal separation, where a mixture of signals are resolved in a factor model. Different samples will contain different signals, some unique, and some shared. The goal might be to visualize samples based on signals they share, or to identify discriminating signals.\n\rIntegrative NMF?\rIntegrative NMF (iNMF) has been proposed for source separation and integration of heterogenous datasets (see LIGER). However, iNMF requires a regularization hyperparameter to enforce integration, and fitting is inherently slow.\nInstead, we can simply run NMF on all signals and then annotate what factors are specific to metadata of interest.\n\rCancer vs. healthy cell signatures\rClassification of cancer cell-of-origin is a great example of source separation. Here, the challenge is to tease out signatures shared by cancer and healthy cell types to discover the cell type from which the cancer originated.\nWe’ll use the aml dataset from the MLdata package:\ndevtools::install_github(\u0026quot;zdebruine/MLdata\u0026quot;)\rdevtools::install_RcppML(\u0026quot;zdebruine/RcppML\u0026quot;)\rlibrary(RcppML)\rlibrary(MLdata)\rlibrary(ggplot2)\rlibrary(cowplot)\rlibrary(umap)\rdata(aml)\rThe MLdata::aml dataset contains samples from 123 patients with Acute Myelogenous Leukemia (AML) and 5 samples each for putative cells of origin (GMP, LMPP, or MEP cells) from healthy patients. Each sample contains information on ~800 differentially methylated regions (DMRs), a measure of gene expression signatures.\ntable(colnames(aml))\r## ## AML sample GMP LMPP MEP ## 123 5 5 5\rSince we have three cell types and cancer, we’ll choose a low factorization rank (k = 5). We’ll fit to machine-tolerances and input ten random seeds so that RcppML::nmf runs factorizations from ten unique random initializations, and returns the best model of the ten:\nnmf_model \u0026lt;- RcppML::nmf(aml, k = 5, tol = 1e-10, maxit = 1000, seed = 1:10, verbose = F)\r\rAnnotating signal sources\rWe can see which sample types are represented in each NMF factor:\nplot(summary(nmf_model, group_by = colnames(aml), stat = \u0026quot;mean\u0026quot;))\rNotice how factor 3 almost exclusively describes methylation signal in healthy cells.\nLet’s plot factor 3 vs. factor 5:\nbiplot(nmf_model, factors = c(3, 5), matrix = \u0026quot;h\u0026quot;, group_by = colnames(aml))\rClearly if we want to “integrate” cancer and healthy cells for the purposes of classifying cell-of-origin, we do not want to be including factor 3 in that analysis.\n\rUMAP on the NMF embedding\rLet’s learn a UMAP embedding of all samples on NMF coordinates using the full NMF model.\nplot_umap \u0026lt;- function(nmf_model){\rset.seed(123)\ru \u0026lt;- uwot::umap(t(nmf_model$h), n_neighbors = 10, metric = \u0026quot;cosine\u0026quot;, min_dist = 0.3, spread = 1)\rdf \u0026lt;- data.frame(\u0026quot;umap1\u0026quot; = u[, 1], \u0026quot;umap2\u0026quot; = u[, 2], \u0026quot;group\u0026quot; = colnames(nmf_model$h))\rggplot(df, aes(x = umap1, y = umap2, color = group)) + geom_point() + theme_void()\r}\rplot_umap(nmf_model)\rClearly there are fundamental differences between cancer and healthy cells.\n\rIntegrating by source separation\rLet’s do the same as we did above, but now excluding factor 3:\nplot_umap(nmf_model[-3])\rBingo! We are able to classify cancer cells based on healthy cell-of-origin!\nIn conclusion, we were able to integrate cancer and healthy cell methylation signatures by finding factors describing variation they shared in common.\n\r","date":1633996800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633996800,"objectID":"790909b56f0712e24d7e9328ad5c3547","permalink":"https://zachdebruine.com/post/integrating-with-nmf/","publishdate":"2021-10-12T00:00:00Z","relpermalink":"/post/integrating-with-nmf/","section":"post","summary":"DNA methylation signatures in patients with Acute Myelogenous Leukemia are compared to healthy cell types to determine cell-of-origin. This is a great example of why source separation is necessary to integrate mixed or heterogenous signals. By using subsets of NMF factors, similarities between these signals are exposed.","tags":["NMF","integration"],"title":"Integrating Heterogenous Samples with NMF","type":"post"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://zachdebruine.com/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]