---
title: "Using tidycensus and leaflet to map Census data"
date: 2017-06-24
slug: "using-tidycensus"
tags: [rstats]
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(cache = TRUE, warning = FALSE, message = FALSE, 
                      echo = TRUE, dpi = 180)
options(width=80, dplyr.width = 150)
library(ggplot2)
library(silgelib)
theme_set(theme_roboto())
```

Recently, I have been following the development and release of Kyle Walker's [tidycensus](https://github.com/walkerke/tidycensus) package. I have been filled with amazement, delight, and well, perhaps another feeling...

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">There should be a word for &quot;the regret felt when an R ðŸ“¦, which would have saved untold hours of your life, is released&quot;â€¦ <a href="https://twitter.com/hashtag/rstats?src=hash">#rstats</a> ðŸ¤” <a href="https://t.co/2THN4MwedO">https://t.co/2THN4MwedO</a></p>&mdash; Mara Averick (@dataandme) <a href="https://twitter.com/dataandme/status/869968290688376832">May 31, 2017</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

But seriously, I have worked with US Census data a lot in the past and this package

- is such a valuable addition to the R ecosystem and
- would have saved me SO MUCH ENERGY, HEADACHE, and TIME.

I was working this weekend on a side project with an old friend about opioid usage in Texas and needed to download some Census data again. A perfect opportunity to give this new package a little run-through!

## Exercising my joygret

Before running code like the following from tidycensus, you need to [obtain an API key](http://api.census.gov/data/key_signup.html) from the Census and then use the function `census_api_key()` to set it in R.

```{r texas_pop}
library(tidyverse)
library(tidycensus)

texas_pop <- get_acs(geography = "county", 
                     variables = "B01003_001", 
                     state = "TX",
                     geometry = TRUE) 

texas_pop
```

There we go! The total population in each county in Texas, in a tidyverse-ready data frame. If you want to get information for multiple states, [just use purrr](https://walkerke.github.io/2017/05/tidycensus-every-tract/). The US Census tabulates lots of [important kinds of information](https://www.census.gov/programs-surveys/acs/guidance/subjects.html) here in the United States, although there has been troubling [uncertainty](https://www.theatlantic.com/politics/archive/2017/05/census-director-resigns-2020-funding-concern/526107/) about [leadership and funding](https://www.washingtonpost.com/local/social-issues/us-census-director-resigns-amid-turmoil-over-funding-of-2020-count/2017/05/09/8f8657c6-34ea-11e7-b412-62beef8121f7_story.html) there in recent months.

So we have this data in a form that will be easy to manipulate; what if we want to map it? Kyle Walker again has this taken care of, with his tigris package (a dependency of tidycensus); if you set `geometry = TRUE` the way that I did when I downloaded the Census data above, tigris handles downloading the shapefiles from the Census, with support for `sf` [simple features](https://github.com/edzer/sfr). Kyle has a vignette for [mapping using ggplot2](https://walkerke.github.io/tidycensus/articles/spatial-data.html), but you can also pipe straight into leaflet.

```{r dependson="texas_pop"}
library(leaflet)
library(stringr)
library(sf)

pal <- colorQuantile(palette = "viridis", domain = texas_pop$estimate, n = 10)

texas_pop %>%
    st_transform(crs = "+init=epsg:4326") %>%
    leaflet(width = "100%") %>%
    addProviderTiles(provider = "CartoDB.Positron") %>%
    addPolygons(popup = ~ str_extract(NAME, "^([^,]*)"),
                stroke = FALSE,
                smoothFactor = 0,
                fillOpacity = 0.7,
                color = ~ pal(estimate)) %>%
    addLegend("bottomright", 
              pal = pal, 
              values = ~ estimate,
              title = "Population percentiles",
              opacity = 1)
```

What is that `st_transform` doing? Well, I am no cartographer and I am still fuzzy on these issues, but it is doing a projection onto a certain reference system of the spatial information contained in the `sf` column. The specific choice of an [EPSG code of 4326](https://gis.stackexchange.com/questions/3334/what-is-the-difference-between-wgs84-and-epsg4326) is for a given projection.

## A couple more examples

Let's look at the counties in Utah (where I live) while we're at it. Let's map color to population here, instead of quantiles, just for something different.

```{r}
utah_pop <- get_acs(geography = "county", 
                    variables = "B01003_001", 
                    state = "UT",
                    geometry = TRUE)

pal <- colorNumeric(palette = "plasma", 
                    domain = utah_pop$estimate)

utah_pop %>%
    st_transform(crs = "+init=epsg:4326") %>%
    leaflet(width = "100%") %>%
    addProviderTiles(provider = "CartoDB.Positron") %>%
    addPolygons(popup = ~ str_extract(NAME, "^([^,]*)"),
                stroke = FALSE,
                smoothFactor = 0,
                fillOpacity = 0.7,
                color = ~ pal(estimate)) %>%
    addLegend("bottomright", 
              pal = pal, 
              values = ~ estimate,
              title = "County Populations",
              opacity = 1)
```

Yep, that is right, although still remarkable to me. Utah is largely an extremely rural state, with lots of people here in Salt Lake City where I live and then in the corridor to the north and south.

There is so much other information available from the Census. For example, what if I want to look at the median home value in Salt Lake County, at the census tract level?

```{r}
slc_value <- get_acs(geography = "tract", 
                    variables = "B25077_001", 
                    state = "UT",
                    county = "Salt Lake County",
                    geometry = TRUE)

pal <- colorNumeric(palette = "viridis", 
                    domain = slc_value$estimate)

slc_value %>%
    st_transform(crs = "+init=epsg:4326") %>%
    leaflet(width = "100%") %>%
    addProviderTiles(provider = "CartoDB.Positron") %>%
    addPolygons(popup = ~ str_extract(NAME, "^([^,]*)"),
                stroke = FALSE,
                smoothFactor = 0,
                fillOpacity = 0.7,
                color = ~ pal(estimate)) %>%
    addLegend("bottomright", 
              pal = pal, 
              values = ~ estimate,
              title = "Median Home Value",
              labFormat = labelFormat(prefix = "$"),
              opacity = 1)
```

The two census tracts with `NA` values are the airport on the west side and the University of Utah on the east side. You can very obviously see the east-to-west gradient that comes as no surprise to us locals, and that priciest tract is up against one of the canyons with beautiful views. But mainly please notice with what ease I made this interactive map!

## The End

Maybe the main reason I wrote up this blog post is to say how streamlined and easy it now is to get Census data into R and plot it, but another reason is to demonstrate, at least to myself, how little effort it takes to make a blog post with, say, interactive leaflet components with my new blogging workflow. I recently changed my blog from a Jekyll blog hosted on GitHub Pages to a blog built with [blogdown](https://github.com/rstudio/blogdown) and [Hugo](https://gohugo.io/), deployed using [Netlify](https://www.netlify.com/). I am finding this workflow so great, and this post with its leaflet maps went off without a hitch! I would like to say a big THANK YOU to Yihui Xie for his work on R Markdown, knitr, and blogdown. Let me know if you have any questions!

